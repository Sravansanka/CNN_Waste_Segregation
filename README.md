
# ğŸ§  CNN Waste Segregation

A CNN-based image classification project focused on automating the segregation of waste into predefined categories. Implemented in Jupyter Notebook using TensorFlow/Keras, this project evaluates three different CNN models and identifies the most effective architecture based on accuracy and loss metrics.

---

## ğŸ“‚ Project Overview

The goal of this project is to develop a robust waste classification model to support automatic waste segregation systems. By training a CNN on labeled waste images, the model predicts the correct category of the waste item (e.g., biodegradable, recyclable, etc.).

---

## ğŸ“Š Dataset Summary

- The dataset is divided into `train`, `test`, and `validation` folders.
- Each folder contains images sorted into category-based subdirectories.
- Images were resized to (64x64) and normalized for CNN processing.

---

## ğŸ—ï¸ Model Architectures Analyzed

## **With Custom Model 1** ğŸ› ï¸

- **Custom Model 1** achieved an overall accuracy of **61%**, showing solid improvement over the baseline. ğŸ“ˆ
- **Cardboard** and **Plastic** had the best performance, with **F1-scores** of **0.73** and **0.69**, respectively. ğŸ“¦ğŸ›¢ï¸
- Lower scores for **Other**, **Paper**, and **Glass** suggest potential confusion or class overlap, which may require further attention. ğŸš§ğŸ“‰

---

## **With Custom Model 2** ğŸ› ï¸ğŸ’¡

- **Custom Model 2** achieved a higher overall accuracy of **66%**, improving across most classes compared to Model 1. ğŸ“ŠğŸ”
- Top-performing classes include **Cardboard** (**F1-score 0.78**) and **Plastic** (**F1-score 0.72**), showing strong consistency. ğŸ“¦ğŸ›¢ï¸
- Performance for **Other** and **Paper** remains moderate, indicating room for refinement in distinguishing these categories. âœ‹ğŸ“œ

---

## **With MobileNet-V2 Model** ğŸ“±ğŸš€

- The **MobileNet V2** customized model achieved an impressive **84% accuracy**, significantly outperforming previous models. ğŸŒŸğŸ“ˆ
- High **F1-scores** across all classes, especially **Cardboard** (**0.92**), **Metal** (**0.90**), and **Food Waste** (**0.86**), reflect strong generalization. ğŸ“¦ğŸ”©ğŸ²
- Even lower-performing classes like **Paper** and **Other** show solid improvements, making this model highly reliable overall. ğŸ“‘ğŸ”„


---

## ğŸ“Œ Conclusion

## **Findings from the Data**

- The dataset consists of images categorized into seven classes: **Metal**, **Other**, **Glass**, **Food Waste**, **Paper**, **Plastic**, and **Cardboard**. ğŸ—‘ï¸ğŸ–¼ï¸

- As shown in the class distribution chart above, the dataset is **imbalanced**, with **Plastic** having the highest number of samples, while **Cardboard** has the fewest. âš–ï¸ğŸ“Š

- This imbalance could lead to biased model predictions, particularly favoring the majority class (**Plastic**). âš ï¸ğŸ”

- To address this, **data augmentation** has been applied to balance the dataset. ğŸ”„âœ¨

- Some classes (such as **Food Waste** and **Plastic**) exhibit considerable variation in appearance, which may complicate classification. ğŸ²ğŸ›¢ï¸

- **Visually similar materials**, like **Plastic** and **Glass**, may confuse the model due to overlapping textures or colors. ğŸ¥¤ğŸ·

- Variations in **image quality** or **lighting conditions** may introduce noise, potentially affecting model performance. ğŸŒ¥ï¸ğŸ“¸

---

## **Model Training and Results**

- A **Convolutional Neural Network (CNN)** was trained from scratch, followed by using a predefined architecture, and ultimately with **augmentation techniques**. ğŸ¤–ğŸ“ˆ

- The input image size was resized to **(128, 128, 3)** to preserve key features. ğŸ–¼ï¸ğŸ”

  **Note:** I attempted to use the dimension **(224, 224, 3)**, but Google Colab crashed multiple times. ğŸ˜µğŸ’»

- The model with predefined layers exhibited **significant improvement** in accuracy and **reduced overfitting**. ğŸ“ŠğŸ”§

- **Callbacks** such as **EarlyStopping**, **ModelCheckpoint**, and **ReduceLROnPlateau** were employed to stabilize and optimize the training process. â±ï¸ğŸ’¡

---

## **Key Insights**

- **Image resolution** and **class balance** have a major impact on the performance of the classification model. ğŸ–¼ï¸âš–ï¸

- Effective use of **callbacks** not only helped preserve the best-performing model but also prevented unnecessary training cycles, optimizing the overall training time. â³ğŸ¯


---

## ğŸš€ How to Run

1. Clone the repository or download the notebook.
2. Ensure the dataset is structured correctly with train/val/test directories.
3. Install dependencies:
   ```bash
   pip install tensorflow matplotlib seaborn
   ```
4. Launch Jupyter Notebook:
   ```bash
   jupyter notebook CNN_Waste_Segregation_SravanaSanka.ipynb
   ```
5. Execute cells sequentially to train and evaluate the models.

---

## ğŸ“š Dependencies

- TensorFlow / Keras
- NumPy
- Matplotlib
- Seaborn
- Jupyter Notebook
- Collab

##ğŸ“¬ Contact
For any queries or collaboration: [Sravana Kumar Sanka]
ğŸ“§ Email: sravan.sanka97@gmail.com
ğŸ”— GitHub: [github.com/Sravansanka/CNN_Waste_Segregation](https://github.com/Sravansanka/CNN_Waste_Segregation)]
